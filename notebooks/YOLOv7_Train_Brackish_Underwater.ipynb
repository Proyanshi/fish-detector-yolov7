{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6912047e",
      "metadata": {
        "id": "6912047e"
      },
      "source": [
        "# YOLOv7 — Brackish Underwater (Roboflow v2)\n",
        "Train & evaluate YOLOv7 on the Roboflow dataset, with PyTorch 2.6+ compatibility patches."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bece3a4",
      "metadata": {
        "id": "0bece3a4"
      },
      "source": [
        "## 1) Environment & GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9a7067f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a7067f1",
        "outputId": "68d8a961-d852-4830-9c5f-a80c724bb173"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python: 3.12.11\n",
            "Torch: 2.8.0+cu126 | CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch, platform\n",
        "print(\"Python:\", platform.python_version())\n",
        "print(\"Torch:\", torch.__version__, \"| CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "538abd5a",
      "metadata": {
        "id": "538abd5a"
      },
      "source": [
        "## 2) Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a6a0ca4b",
      "metadata": {
        "id": "a6a0ca4b"
      },
      "outputs": [],
      "source": [
        "# Install dependencies for local Windows environment\n",
        "import sys, subprocess\n",
        "def pip_install(pkgs):\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--upgrade', 'pip', 'wheel', 'setuptools'])\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install'] + pkgs)\n",
        "try:\n",
        "    pip_install(['roboflow', 'thop', 'opencv-python-headless', 'matplotlib', 'pyyaml', 'tqdm', 'seaborn', 'pycocotools', 'jedi>=0.16'])\n",
        "except Exception as e:\n",
        "    print('Error installing packages:', e)\n",
        "    print('If pycocotools fails, try installing cython and cocoapi manually:')\n",
        "    print('pip install cython')\n",
        "    print('pip install git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ed14905",
      "metadata": {
        "id": "7ed14905"
      },
      "source": [
        "## 3) Get YOLOv7 repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d15a2413",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d15a2413",
        "outputId": "729d3604-7094-4ae5-975c-f078ccf9e6bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloned: /content/yolov7\n",
            "pycocotools wheel installed.\n",
            "\n",
            "✅ YOLOv7 environment ready. You can now run train/test scripts under /content/yolov7\n"
          ]
        }
      ],
      "source": [
        "# One-shot, robust YOLOv7 setup for local Windows/venv\n",
        "import os, sys, shutil, subprocess, pathlib\n",
        "REPO_URL = \"https://github.com/WongKinYiu/yolov7.git\"\n",
        "REPO_DIR = os.path.join(os.getcwd(), 'yolov7')\n",
        "# Fresh clone\n",
        "if os.path.exists(REPO_DIR):\n",
        "    shutil.rmtree(REPO_DIR)\n",
        "subprocess.check_call([\"git\", \"clone\", REPO_URL, REPO_DIR])\n",
        "print(\"Cloned to:\", REPO_DIR)\n",
        "# Upgrade build tools using the active Python interpreter\n",
        "subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--upgrade', 'pip', 'setuptools', 'wheel'])\n",
        "# Install known-good deps explicitly (skip torch to avoid downgrades/breakage)\n",
        "BASE_PKGS = [\n",
        "    'numpy>=1.26', 'pandas>=2.0', 'matplotlib>=3.8', 'seaborn>=0.13',\n",
        "    'tqdm>=4.66', 'scipy>=1.11', 'Pillow>=10.0', 'requests>=2.31', 'PyYAML>=6.0',\n",
        "    'opencv-python-headless>=4.8', 'tensorboard>=2.14', 'thop>=0.1.1.post2209072238',\n",
        "    'protobuf<5',\n",
        "]\n",
        "subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--no-cache-dir', *BASE_PKGS])\n",
        "# Try pycocotools wheel first; if not, build from source\n",
        "def install_pycocotools():\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'pycocotools>=2.0.7'])\n",
        "        print('pycocotools wheel installed.')\n",
        "        return\n",
        "    except Exception:\n",
        "        print('Wheel unavailable; attempting source build...')\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'cython'])\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'])\n",
        "        print('pycocotools built from official COCOAPI.')\n",
        "    except Exception:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI'])\n",
        "        print('pycocotools installed from fallback fork.')\n",
        "install_pycocotools()\n",
        "print('\n",
        "print(\"\\n✅ YOLOv7 environment ready. You can now run train/test scripts under /content/yolov7\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b235178",
      "metadata": {
        "id": "1b235178"
      },
      "source": [
        "## 4) Download dataset from Roboflow (version 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "29ef45df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29ef45df",
        "outputId": "7aacbcd3-68c4-4122-b707-7af970fd16a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in Brackish-Underwater-2 to yolov7pytorch:: 100%|██████████| 354043/354043 [00:05<00:00, 68206.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Brackish-Underwater-2 in yolov7pytorch:: 100%|██████████| 29360/29360 [00:05<00:00, 5521.14it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset directory: /content/Brackish-Underwater-2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Provided snippet\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"tAn8GdtOiAqVLCvRWI7Y\")\n",
        "project = rf.workspace(\"brad-dwyer\").project(\"brackish-underwater\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolov7\")  # returns a Dataset object with .location\n",
        "\n",
        "DATA_DIR = dataset.location  # e.g., '/content/brackish-underwater-2'\n",
        "print(\"Dataset directory:\", DATA_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "203a2db2",
      "metadata": {
        "id": "203a2db2"
      },
      "source": [
        "## 5) Locate data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5406a230",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5406a230",
        "outputId": "1d3011f5-17ac-41ee-bc1e-b969b2ec1ba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using data.yaml: /content/Brackish-Underwater-2/data.yaml\n"
          ]
        }
      ],
      "source": [
        "import os, glob, json\n",
        "data_yaml = None\n",
        "# Common locations from Roboflow export\n",
        "for cand in [\n",
        "    os.path.join(DATA_DIR, \"data.yaml\"),\n",
        "    os.path.join(DATA_DIR, \"data.yaml\".lower()),\n",
        "]:\n",
        "    if os.path.exists(cand):\n",
        "        data_yaml = cand\n",
        "        break\n",
        "if not data_yaml:\n",
        "    # fallback: search\n",
        "    cands = glob.glob(os.path.join(DATA_DIR, \"**\", \"data.yaml\"), recursive=True)\n",
        "    if cands: data_yaml = cands[0]\n",
        "\n",
        "assert data_yaml and os.path.exists(data_yaml), \"Could not find data.yaml in the downloaded dataset.\"\n",
        "print(\"Using data.yaml:\", data_yaml)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3f6a74e",
      "metadata": {
        "id": "d3f6a74e"
      },
      "source": [
        "### (Optional) Inspect class names from YAML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "51e2e5ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51e2e5ef",
        "outputId": "38ad9bc2-69af-4e9b-cf52-26f062dca39c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes (nc): 6\n",
            "Names: ['crab', 'fish', 'jellyfish', 'shrimp', 'small_fish', 'starfish']\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "with open(data_yaml) as f:\n",
        "    y = yaml.safe_load(f)\n",
        "print(\"Classes (nc):\", y.get(\"nc\"))\n",
        "print(\"Names:\", y.get(\"names\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b35ff727",
      "metadata": {
        "id": "b35ff727"
      },
      "source": [
        "## 6) Get base weights (yolov7.pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66ac8098",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66ac8098",
        "outputId": "e876cd2c-8b87-46fa-f015-c50997b83b5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/yolov7\n",
            "Weights present: /content/yolov7/yolov7.pt\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os, pathlib, sys, subprocess\n",
        "# Ensure we're in the repository directory if it exists\n",
        "repo_dir = os.path.join(os.getcwd(), 'yolov7')\n",
        "if os.path.exists(repo_dir):\n",
        "    os.chdir(repo_dir)\n",
        "weights_path = os.path.join(os.getcwd(), 'yolov7.pt')\n",
        "if not os.path.exists(weights_path):\n",
        "    # Download official release weight\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'wget'])\n",
        "        import wget\n",
        "        wget.download('https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt', weights_path)\n",
        "    except Exception:\n",
        "        # fallback to urllib\n",
        "        from urllib.request import urlretrieve\n",
        "        urlretrieve('https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt', weights_path)\n",
        "print('Weights present:', os.path.abspath(weights_path))\n",
        "# Return to original cwd\n",
        "os.chdir(pathlib.Path(repo_dir).parent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a38759e",
      "metadata": {
        "id": "8a38759e"
      },
      "source": [
        "## 7) Train\n",
        "Default settings target a T4 with 640×640 images. Adjust batch size if you see OOM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oatQ2b5ame4r",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oatQ2b5ame4r",
        "outputId": "404346fa-e8e0-4510-8dba-fd9464b23bcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/yolov7\n",
            "Patched train.py: autocast -> torch.amp.autocast + step cap inserted\n",
            "Using data.yaml: /content/data_abs.yaml\n",
            "train: /content/Brackish-Underwater-2/train/images\n",
            "val:   /content/Brackish-Underwater-2/valid/images\n",
            "test:  /content/Brackish-Underwater-2/test/images\n",
            "Removed cache: /content/Brackish-Underwater-2/valid/labels.cache\n",
            "Removed cache: /content/Brackish-Underwater-2/train/labels.cache\n",
            "\n",
            "Launching training with step cap = 200 ...\n",
            "\n",
            "2025-08-31 19:36:23.509494: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756668983.529321    9340 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756668983.535290    9340 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756668983.550183    9340 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756668983.550212    9340 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756668983.550216    9340 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756668983.550219    9340 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-31 19:36:23.554786: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "YOLOR 🚀 v0.1-128-ga207844 torch 2.8.0+cu126 CUDA:0 (Tesla T4, 15095.0625MB)\n",
            "\n",
            "Namespace(weights='', cfg='cfg/training/yolov7-tiny.yaml', data='/content/data_abs.yaml', hyp='data/hyp.scratch.p5.yaml', epochs=50, batch_size=16, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='urpc2019_yolov7', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/urpc2019_yolov72', total_batch_size=16)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpriyanshi-chaudhary3\u001b[0m (\u001b[33mpriyanshi-chaudhary3-amity-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/yolov7/wandb/run-20250831_193630-zz0utowc\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33murpc2019_yolov72\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/priyanshi-chaudhary3-amity-university/YOLOR\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/priyanshi-chaudhary3-amity-university/YOLOR/runs/zz0utowc\u001b[0m\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  2                -1  1      2112  models.common.Conv                      [64, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  3                -2  1      2112  models.common.Conv                      [64, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  4                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  5                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  6  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            "  7                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  8                -1  1         0  models.common.MP                        []                            \n",
            "  9                -1  1      4224  models.common.Conv                      [64, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 10                -2  1      4224  models.common.Conv                      [64, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 11                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 12                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 13  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 15                -1  1         0  models.common.MP                        []                            \n",
            " 16                -1  1     16640  models.common.Conv                      [128, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 17                -2  1     16640  models.common.Conv                      [128, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 20  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 22                -1  1         0  models.common.MP                        []                            \n",
            " 23                -1  1     66048  models.common.Conv                      [256, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 24                -2  1     66048  models.common.Conv                      [256, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 25                -1  1    590336  models.common.Conv                      [256, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 26                -1  1    590336  models.common.Conv                      [256, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 27  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 28                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 29                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 30                -2  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 31                -1  1         0  models.common.SP                        [5]                           \n",
            " 32                -2  1         0  models.common.SP                        [9]                           \n",
            " 33                -3  1         0  models.common.SP                        [13]                          \n",
            " 34  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 35                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 36          [-1, -7]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 38                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 39                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 40                21  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 41          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 42                -1  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 43                -2  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 44                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 45                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 46  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 47                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 48                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 49                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 50                14  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 51          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 52                -1  1      4160  models.common.Conv                      [128, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 53                -2  1      4160  models.common.Conv                      [128, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 54                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 55                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 56  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 57                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 58                -1  1     73984  models.common.Conv                      [64, 128, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 59          [-1, 47]  1         0  models.common.Concat                    [1]                           \n",
            " 60                -1  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 61                -2  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 62                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 63                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 64  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 65                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 66                -1  1    295424  models.common.Conv                      [128, 256, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 67          [-1, 37]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     65792  models.common.Conv                      [512, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 69                -2  1     65792  models.common.Conv                      [512, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 70                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 71                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 72  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 73                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 74                57  1     73984  models.common.Conv                      [64, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 75                65  1    295424  models.common.Conv                      [128, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 76                73  1   1180672  models.common.Conv                      [256, 512, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 77      [74, 75, 76]  1     30662  models.yolo.IDetect                     [6, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4322.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 263 layers, 6028518 parameters, 6028518 gradients, 13.2 GFLOPS\n",
            "\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 58 .bias, 58 conv.weight, 61 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/Brackish-Underwater-2/train/labels' images and labels... 11739 found, 0 missing, 1772 empty, 0 corrupted: 100% 11739/11739 [00:03<00:00, 3480.53it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Brackish-Underwater-2/train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/Brackish-Underwater-2/valid/labels' images and labels... 1467 found, 0 missing, 229 empty, 0 corrupted: 100% 1467/1467 [00:01<00:00, 1376.47it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Brackish-Underwater-2/valid/labels.cache\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.04, Best Possible Recall (BPR) = 1.0000\n",
            "/content/yolov7/train.py:299: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = amp.GradScaler(enabled=cuda)\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/urpc2019_yolov72\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      0/49    0.656G   0.07919   0.01044   0.02697    0.1166        59       640: 100% 734/734 [07:50<00:00,  1.56it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 46/46 [00:13<00:00,  3.43it/s]\n",
            "                 all        1467           0           0           0           0           0\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      1/49     2.85G   0.07111  0.009874   0.02173    0.1027        90       640:  72% 531/734 [05:04<01:44,  1.95it/s]"
          ]
        }
      ],
      "source": [
        "# Train YOLOv7 (URPC-style) BUT:\n",
        "# - Switch deprecated autocast -> torch.amp.autocast('cuda', enabled=cuda)\n",
        "# - Cap steps per epoch at 200 (so progress bar shows ~200 iters, not 734)\n",
        "# - Keep robust data.yaml absolutization & cache cleanup\n",
        "\n",
        "import os, glob, shutil, yaml, pathlib, re\n",
        "\n",
        "# -------- 0) PyTorch 2.6+ serialization allowlist --------\n",
        "import torch, torch.serialization\n",
        "torch.serialization.add_safe_globals(['numpy._core.multiarray._reconstruct'])\n",
        "\n",
        "# -------- 1) Limit steps per epoch --------\n",
        "os.environ[\"MAX_STEPS_PER_EPOCH\"] = \"200\"  # change if you want a different cap\n",
        "\n",
        "# -------- 2) cd into repo --------\n",
        "import sys\n",
        "repo_dir = os.path.join(os.getcwd(), 'yolov7')\n",
        "if os.path.exists(repo_dir):\n",
        "    os.chdir(repo_dir)\n",
        "\n",
        "# -------- 3) Patch train.py for new autocast + step cap --------\n",
        "train_py = \"/content/yolov7/train.py\"\n",
        "with open(train_py, \"r\", encoding=\"utf-8\") as f:\n",
        "    src = f.read()\n",
        "\n",
        "# (a) Replace deprecated autocast usage\n",
        "src_new = re.sub(\n",
        "    r\"with\\s+amp\\.autocast\\s*\\(\\s*enabled\\s*=\\s*cuda\\s*\\)\\s*:\",\n",
        "    \"with torch.amp.autocast('cuda', enabled=cuda):\",\n",
        "    src,\n",
        ")\n",
        "\n",
        "# (b) Insert a step cap right after the main dataloader loop begins\n",
        "# Match the common loop signature in YOLOv7:\n",
        "loop_pat = r\"(for\\s+i,\\s*\\(imgs,\\s*targets,\\s*paths,\\s*_\\)\\s+in\\s+enumerate\\(\\s*dataloader\\s*\\)\\s*:\\s*\\n)\"\n",
        "inject = (\n",
        "    r\"\\1\"\n",
        "    r\"        # --- injected limit to cap steps per epoch ---\\n\"\n",
        "    r\"        max_steps = int(os.getenv('MAX_STEPS_PER_EPOCH', '0'))\\n\"\n",
        "    r\"        if max_steps > 0 and i >= max_steps:\\n\"\n",
        "    r\"            break\\n\"\n",
        ")\n",
        "if re.search(loop_pat, src_new):\n",
        "    src_new = re.sub(loop_pat, inject, src_new)\n",
        "else:\n",
        "    # Fallback: try a slightly looser pattern\n",
        "    loop_pat2 = r\"(for\\s+i.*in\\s+enumerate\\(\\s*dataloader\\s*\\)\\s*:\\s*\\n)\"\n",
        "    src_new = re.sub(loop_pat2, inject, src_new)\n",
        "\n",
        "if src_new != src:\n",
        "    with open(train_py, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(src_new)\n",
        "    print(\"Patched train.py: autocast -> torch.amp.autocast + step cap inserted\")\n",
        "else:\n",
        "    print(\"No changes applied to train.py (patterns not found or already patched)\")\n",
        "\n",
        "# -------- 4) Settings --------\n",
        "CFG      = os.getenv('CFG', 'cfg/training/yolov7-tiny.yaml')\n",
        "WEIGHTS  = os.getenv('WEIGHTS', '')            # '' => train from scratch\n",
        "EPOCHS   = int(os.getenv('EPOCHS', 50))\n",
        "IMG_SIZE = int(os.getenv('IMG_SIZE', 640))\n",
        "BATCH    = int(os.getenv('BATCH', 16))\n",
        "RUN_NAME = os.getenv('RUN_NAME', 'urpc2019_yolov7')\n",
        "\n",
        "# Disable W&B unless a key is present\n",
        "if not os.getenv(\"WANDB_API_KEY\", \"\"):\n",
        "    os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# -------- 5) Normalize data.yaml to absolute paths --------\n",
        "if 'dataset' in globals() and hasattr(dataset, 'location'):\n",
        "    orig_yaml = os.path.join(dataset.location, 'data.yaml')\n",
        "else:\n",
        "    orig_yaml = '/content/Brackish-Underwater-2/data.yaml'\n",
        "assert os.path.exists(orig_yaml), f\"data.yaml not found at: {orig_yaml}\"\n",
        "\n",
        "with open(orig_yaml) as f:\n",
        "    y = yaml.safe_load(f)\n",
        "\n",
        "base = pathlib.Path(orig_yaml).parent\n",
        "root = base.parent\n",
        "ds_name = base.name\n",
        "\n",
        "def _make_abs_roboflow(p: str):\n",
        "    if not p: return None\n",
        "    p = str(p)\n",
        "    if os.path.isabs(p): return p\n",
        "    cand = (root / p) if p.startswith(ds_name + \"/\") else (base / p)\n",
        "    if not cand.exists():\n",
        "        a = base / p; b = root / p\n",
        "        cand = a if a.exists() else (b if b.exists() else cand)\n",
        "    return str(cand.resolve())\n",
        "\n",
        "for k in (\"train\", \"val\", \"valid\", \"test\"):\n",
        "    if k in y and y[k]:\n",
        "        y[k] = _make_abs_roboflow(y[k])\n",
        "if not y.get(\"val\") and y.get(\"valid\"):\n",
        "    y[\"val\"] = y[\"valid\"]\n",
        "\n",
        "test_dir = os.path.join(base, \"test\", \"images\")\n",
        "if not y.get(\"test\") and os.path.exists(test_dir):\n",
        "    y[\"test\"] = test_dir\n",
        "\n",
        "patched_yaml = \"/content/data_abs.yaml\"\n",
        "with open(patched_yaml, \"w\") as f:\n",
        "    yaml.safe_dump(y, f, sort_keys=False)\n",
        "\n",
        "print(\"Using data.yaml:\", patched_yaml)\n",
        "print(\"train:\", y.get(\"train\"))\n",
        "print(\"val:  \", y.get(\"val\"))\n",
        "print(\"test: \", y.get(\"test\"))\n",
        "\n",
        "assert y.get(\"train\") and os.path.exists(y[\"train\"]), f\"Train path missing: {y.get('train')}\"\n",
        "assert y.get(\"val\") and os.path.exists(y[\"val\"]), f\"Val path missing: {y.get('val')}\"\n",
        "\n",
        "# -------- 6) Clear stale caches --------\n",
        "for d in [str(base), \"/content\"]:\n",
        "    for p in glob.glob(os.path.join(d, \"**\", \"*.cache\"), recursive=True):\n",
        "        try:\n",
        "            os.remove(p)\n",
        "            print(\"Removed cache:\", p)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "# -------- 7) Launch training (note: --img is correct flag for yolov7) --------\n",
        "print('\\nLaunching training with step cap =', os.environ['MAX_STEPS_PER_EPOCH'], '...\\n')\n",
        "import shlex, subprocess\n",
        "train_cmd = [sys.executable, 'train.py', '--workers', '8', '--device', '0', '--batch-size', str(BATCH), '--epochs', str(EPOCHS), '--img', str(IMG_SIZE), str(IMG_SIZE), '--data', patched_yaml, '--cfg', CFG, '--weights', WEIGHTS or 'yolov7.pt', '--name', RUN_NAME]\n",
        "print('Running:', ' '.join(shlex.quote(a) for a in train_cmd))\n",
        "subprocess.check_call(train_cmd)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SW5HlpwToEfk",
      "metadata": {
        "id": "SW5HlpwToEfk"
      },
      "source": [
        "### 8) Post-Training Evaluation\n",
        "This step runs validation using the best weights from training.  \n",
        "It will report:\n",
        "\n",
        "- Number of layers  \n",
        "- Total number of parameters  \n",
        "- GFLOPS  \n",
        "- FPS  \n",
        "- Mean Average Precision (mAP)  \n",
        "- Average Precision (per class)  \n",
        "- Recall  \n",
        "- F1 score  \n",
        "- Confusion matrix (saved as image)  \n",
        "- Architecture details summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfIFGzYGoCcs",
      "metadata": {
        "id": "bfIFGzYGoCcs"
      },
      "outputs": [],
      "source": [
        "# === Post-training evaluation & metrics harvest (YOLOv7) ===\n",
        "import os, sys, glob, shlex, subprocess, re, csv, json, pathlib\n",
        "from collections import OrderedDict\n",
        "\n",
        "y7 = \"/content/yolov7\"\n",
        "RUN_NAME = \"urpc2019_yolov7\"   # change if you used a different --name\n",
        "DATA_YAML = \"/content/data_abs.yaml\"\n",
        "\n",
        "# 1) Locate best.pt (prefer run name, fallback to exp*)\n",
        "train_dirs = sorted(\n",
        "    glob.glob(os.path.join(y7, \"runs\", \"train\", f\"{RUN_NAME}*\")) +\n",
        "    glob.glob(os.path.join(y7, \"runs\", \"train\", \"exp*\")),\n",
        "    key=os.path.getmtime\n",
        ")\n",
        "assert train_dirs, \"No training runs found.\"\n",
        "last_train = train_dirs[-1]\n",
        "best = os.path.join(last_train, \"weights\", \"best.pt\")\n",
        "if not os.path.exists(best):\n",
        "    best = os.path.join(last_train, \"weights\", \"last.pt\")\n",
        "assert os.path.exists(best), f\"No weights found at {best}\"\n",
        "print(\"Using weights:\", best)\n",
        "print(\"Train dir:\", last_train)\n",
        "\n",
        "# 2) Reprint model summary (#layers, #params, GFLOPS) by building the model once\n",
        "#    (works even if test didn't print it)\n",
        "sys.path.insert(0, y7)\n",
        "from models.experimental import attempt_load\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = attempt_load(best, map_location=device)  # our repo already handles weights_only in your earlier patches\n",
        "model.eval()\n",
        "# Count layers & params\n",
        "num_layers = sum(1 for _ in model.modules())\n",
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "# Try to compute MACs/Flops via forward hooks is heavy; rely on YOLOv7 printed GFLOPS if available in log.\n",
        "# We'll parse training log for GFLOPS line as fallback.\n",
        "gflops = None\n",
        "for log_path in [os.path.join(last_train, \"opt.yaml\"),\n",
        "                 os.path.join(last_train, \"results.txt\"),\n",
        "                 os.path.join(y7, \"runs\", \"train\", RUN_NAME, \"results.txt\")]:\n",
        "    pass  # placeholders\n",
        "\n",
        "# Parse GFLOPS from the console logs captured in results.txt (YOLOv7 writes one line with 'GFLOPS')\n",
        "gflops_re = re.compile(r\"Model Summary:\\s*\\d+\\s*layers,\\s*[\\d,]+\\s*parameters.*?([0-9]*\\.?[0-9]+)\\s*GFLOPS\", re.I)\n",
        "gflops_scan_files = []\n",
        "# Try typical train console capture (not always saved). We’ll scan recent W&B logs and the notebook output dir.\n",
        "cand_logs = glob.glob(os.path.join(last_train, \"*.log\")) + glob.glob(os.path.join(y7, \"wandb\", \"run-*\", \"logs\", \"debug.log\"))\n",
        "for p in cand_logs[::-1]:\n",
        "    try:\n",
        "        with open(p, \"r\", errors=\"ignore\") as f:\n",
        "            m = gflops_re.search(f.read())\n",
        "        if m:\n",
        "            gflops = float(m.group(1))\n",
        "            break\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# 3) Run validation; capture output to parse speed (FPS) & ensure plots are saved (confusion matrix)\n",
        "val_cmd = [\n",
        "    sys.executable, os.path.join(y7, \"test.py\"),\n",
        "    \"--weights\", best,\n",
        "    \"--data\", DATA_YAML,\n",
        "    \"--img-size\", \"640\",\n",
        "    \"--batch-size\", \"16\",\n",
        "    \"--conf-thres\", \"0.001\",\n",
        "    \"--iou-thres\", \"0.65\",\n",
        "    \"--task\", \"val\",\n",
        "    \"--save-json\",\n",
        "    \"--plots\",\n",
        "    \"--device\", \"0\" if torch.cuda.is_available() else \"cpu\"\n",
        "]\n",
        "print(\"Running val:\", \" \".join(shlex.quote(a) for a in val_cmd))\n",
        "proc = subprocess.run(val_cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "print(proc.stdout)\n",
        "\n",
        "# 4) Where test results live\n",
        "test_dirs = sorted(glob.glob(os.path.join(y7, \"runs\", \"test\", \"exp*\")), key=os.path.getmtime)\n",
        "assert test_dirs, \"No test runs found; check the val logs above.\"\n",
        "last_test = test_dirs[-1]\n",
        "print(\"Test dir:\", last_test)\n",
        "\n",
        "# 5) Parse Speed for FPS (line like: 'Speed: 1.4ms pre-process, 3.1ms inference, 1.0ms NMS per image')\n",
        "speed_line = None\n",
        "for line in proc.stdout.splitlines()[::-1]:\n",
        "    if \"Speed:\" in line and \"inference\" in line and \"NMS\" in line:\n",
        "        speed_line = line.strip()\n",
        "        break\n",
        "\n",
        "fps = None\n",
        "if speed_line:\n",
        "    # Extract inference and NMS ms\n",
        "    m = re.search(r\"inference,\\s*([0-9.]+)ms.*?NMS\\s*([0-9.]+)ms\", speed_line)\n",
        "    if m:\n",
        "        inf_ms = float(m.group(1))\n",
        "        nms_ms = float(m.group(2))\n",
        "        per_img_ms = inf_ms + nms_ms\n",
        "        if per_img_ms > 0:\n",
        "            fps = 1000.0 / per_img_ms\n",
        "\n",
        "# 6) Parse metrics from results.txt (YOLOv7 writes a CSV-like txt with header)\n",
        "results_txt = os.path.join(last_test, \"results.txt\")\n",
        "metrics = OrderedDict()\n",
        "if os.path.exists(results_txt):\n",
        "    with open(results_txt, \"r\") as f:\n",
        "        rows = [r.strip() for r in f.readlines() if r.strip()]\n",
        "    # The last row has the final metrics\n",
        "    header = rows[0].split()\n",
        "    vals   = rows[-1].split()\n",
        "    # YOLOv7 results.txt header example:  epoch, GIoU, obj, cls, total, P, R, mAP@.5, mAP@.5:.95\n",
        "    # We’ll map known names if present:\n",
        "    try:\n",
        "        idx = {h:i for i,h in enumerate(header)}\n",
        "        def getf(name, default=None):\n",
        "            return float(vals[idx[name]]) if name in idx else default\n",
        "        metrics[\"Precision\"] = getf(\"P\")\n",
        "        metrics[\"Recall\"] = getf(\"R\")\n",
        "        metrics[\"mAP@0.5\"] = getf(\"mAP@.5\") or getf(\"mAP@0.5\")\n",
        "        metrics[\"mAP@0.5:0.95\"] = getf(\"mAP@.5:.95\") or getf(\"mAP@0.5:0.95\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# 7) Per-class AP, Confusion Matrix, F1, etc.\n",
        "# YOLOv7 writes per-class PR-curves and confusion matrix to the test dir.\n",
        "conf_mat_png = glob.glob(os.path.join(last_test, \"*confusion_matrix.png\"))\n",
        "conf_mat_png = conf_mat_png[0] if conf_mat_png else None\n",
        "# Per-class stats CSV (if present)\n",
        "per_class_csv = glob.glob(os.path.join(last_test, \"labels_*.csv\"))  # sometimes saved; else skip\n",
        "per_class_ap = {}\n",
        "if per_class_csv:\n",
        "    try:\n",
        "        with open(per_class_csv[0], \"r\") as f:\n",
        "            rdr = csv.DictReader(f)\n",
        "            for row in rdr:\n",
        "                cls = row.get(\"class\") or row.get(\"Class\") or row.get(\"name\") or row.get(\"Name\")\n",
        "                ap50 = row.get(\"AP@0.50\") or row.get(\"AP@.50\") or row.get(\"AP50\")\n",
        "                if cls and ap50:\n",
        "                    per_class_ap[cls] = float(ap50)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# F1: If not directly provided, approximate best-F1 from PR curve isn’t trivial to re-derive here.\n",
        "# We’ll compute F1 from global P/R if available (this is just one operating point).\n",
        "f1 = None\n",
        "if metrics.get(\"Precision\") is not None and metrics.get(\"Recall\") is not None:\n",
        "    P = metrics[\"Precision\"]; R = metrics[\"Recall\"]\n",
        "    if (P + R) > 0:\n",
        "        f1 = 2 * P * R / (P + R)\n",
        "\n",
        "# 8) Print summary\n",
        "print(\"\\n=== Summary ===\")\n",
        "print(f\"Architecture: {model.yaml.get('arch','YOLOv7')} ({model.yaml.get('depth_multiple','?')} depth, {model.yaml.get('width_multiple','?')} width)\")\n",
        "print(f\"Layers: {num_layers}\")\n",
        "print(f\"Parameters: {num_params:,}\")\n",
        "print(f\"GFLOPS: {gflops if gflops is not None else 'see training log'}\")\n",
        "print(f\"FPS (approx from val speed): {fps:.2f}\" if fps else \"FPS: not available (no speed line parsed)\")\n",
        "if metrics:\n",
        "    for k,v in metrics.items():\n",
        "        if v is not None:\n",
        "            print(f\"{k}: {v:.4f}\")\n",
        "        else:\n",
        "            print(f\"{k}: N/A\")\n",
        "if f1 is not None:\n",
        "    print(f\"F1 (from global P/R): {f1:.4f}\")\n",
        "else:\n",
        "    print(\"F1: N/A\")\n",
        "\n",
        "if per_class_ap:\n",
        "    print(\"\\nAverage Precision per class (AP@0.50):\")\n",
        "    for k,v in per_class_ap.items():\n",
        "        print(f\"  {k}: {v:.4f}\")\n",
        "else:\n",
        "    print(\"\\nPer-class AP file not found; check plots in:\", last_test)\n",
        "\n",
        "print(\"\\nConfusion matrix image:\", conf_mat_png if conf_mat_png else \"not found (check test dir)\")\n",
        "print(\"Test directory:\", last_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Rc5D29hmqvwk",
      "metadata": {
        "id": "Rc5D29hmqvwk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Define the path to your Brackish test images (update to your local path, e.g., 'C:/path/to/Brackish-Underwater-2/test/images')\n",
        "test_images_path = os.path.join(os.getcwd(), 'Brackish-Underwater-2', 'test', 'images')\n",
        "\n",
        "# Get a list of all image files in the test directory\n",
        "all_test_images = glob.glob(os.path.join(test_images_path, '*.jpg')) + \\\n",
        "                  glob.glob(os.path.join(test_images_path, '*.jpeg')) + \\\n",
        "                  glob.glob(os.path.join(test_images_path, '*.png'))\n",
        "\n",
        "# Check if there are enough test images\n",
        "if len(all_test_images) < 50:\n",
        "    print(f\"⚠️ Warning: Only {len(all_test_images)} test images found. Zipping all of them.\")\n",
        "    images_to_zip = all_test_images\n",
        "else:\n",
        "    # Select 50 random test images\n",
        "    images_to_zip = random.sample(all_test_images, 50)\n",
        "\n",
        "# Create a temporary directory to store the selected images\n",
        "zip_dir = '/content/selected_brackish_test_images'\n",
        "os.makedirs(zip_dir, exist_ok=True)\n",
        "\n",
        "# Copy the selected images to the temporary directory\n",
        "for img_path in images_to_zip:\n",
        "    shutil.copy(img_path, zip_dir)\n",
        "\n",
        "# Zip the temporary directory\n",
        "zip_filename = 'brackish_selected_test_images.zip'\n",
        "shutil.make_archive(zip_filename.replace('.zip', ''), 'zip', zip_dir)\n",
        "\n",
        "print(f'✅ Created {zip_filename} in the current working directory. Transfer it from the notebook's folder to your local machine if needed.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r5KIJk88qzSE",
      "metadata": {
        "id": "r5KIJk88qzSE"
      },
      "outputs": [],
      "source": [
        "# You can use this cell to download the zip file after the previous cell finishes\n",
        "from google.colab import files\n",
        "files.download('brackish_selected_test_images.zip')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
